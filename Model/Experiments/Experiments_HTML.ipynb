{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuned Bert-base Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(\"../../Model\")\n",
    "# print(os.getcwd())\n",
    "# for path in sys.path:\n",
    "#     print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/m2021ttakayanagi/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Experiments\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from transformer import transformers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSentence_Level_Transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_gpu\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrun\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Sentence_Level_Transformers/run_gpu.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ipdb.set_trace()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Customized Transformers Util\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSentence_Level_Transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m d, here, mask_\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSentence_Level_Transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers_gpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Sentence_Level_Transformers/custom_transformers/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelfAttention, TransformerBlock\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTransformer, CTransformer\n",
      "File \u001b[0;32m~/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Sentence_Level_Transformers/custom_transformers/modules.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mask_\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'custom_transformers'"
     ]
    }
   ],
   "source": [
    "# from transformer import transformers\n",
    "import transformers\n",
    "from Sentence_Level_Transformers import run_gpu\n",
    "import run\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-only HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024, # 1024(textual feature)\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./3days_embds_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_3days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_3days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/3_days_result_-1.csv')\n",
    "\n",
    "best_alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_7days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_7days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "\n",
    "best_alpha\n",
    "best_alpha.to_csv('./results/7_days_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_15days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_15days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/15_days_result.csv')\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_30days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_30days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/30_days_result.csv')\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
