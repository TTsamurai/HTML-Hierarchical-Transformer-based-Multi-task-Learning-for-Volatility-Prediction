{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuned Bert-base Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(\"../../Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/m2021ttakayanagi/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 14:45:17.080531: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-08 14:45:17.115860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 14:45:17.726951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# from transformer import transformers\n",
    "import transformers\n",
    "from Sentence_Level_Transformers import run_gpu\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-only HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Data ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './3days_embds_padding_large.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m args \u001b[38;5;241m=\u001b[39m easydict\u001b[38;5;241m.\u001b[39mEasyDict({\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m})\n\u001b[0;32m---> 31\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults in alpha = \u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluation)\n",
      "File \u001b[0;32m~/Documents/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/Model/Sentence_Level_Transformers/run_gpu.py:69\u001b[0m, in \u001b[0;36mgo\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     66\u001b[0m NUM_CLS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Loading Data ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m TEXT_emb \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m LABEL_emb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(arg\u001b[38;5;241m.\u001b[39mlabel_dir)\n\u001b[1;32m     71\u001b[0m LABEL_emb_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(arg\u001b[38;5;241m.\u001b[39mlabel_dir_b)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './3days_embds_padding_large.npy'"
     ]
    }
   ],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024, # 1024(textual feature)\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./3days_embds_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_3days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_3days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False})\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/3_days_result_-1.csv')\n",
    "\n",
    "best_alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_7days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_7days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "\n",
    "best_alpha\n",
    "best_alpha.to_csv('./results/7_days_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_15days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_15days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/15_days_result.csv')\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30-days-text-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = {'alpha': [],'best':[]}\n",
    "for i in np.arange(0.1,1.1,0.1):   \n",
    "    if __name__ == \"__main__\":\n",
    "        #print('OPTIONS ', options)\n",
    "        # Tuning Parameters: \n",
    "        import easydict\n",
    "        from argparse import ArgumentParser\n",
    "        parser = ArgumentParser()\n",
    "        args = parser.parse_known_args()[0]\n",
    "        args = easydict.EasyDict({\n",
    "                \"num_epochs\": 10,\n",
    "                \"batch_size\": 4,\n",
    "                \"lr\": 2e-5,\n",
    "                \"tb_dir\": \"./runs\",\n",
    "                \"final\": False,\n",
    "                \"max_pool\": False,\n",
    "                \"embedding_size\" : 1024,\n",
    "                \"vocab_size\" : 50000,\n",
    "                \"max_length\" : 520,\n",
    "                \"num_heads\" : 2,\n",
    "                \"depth\" : 2,\n",
    "                \"seed\" : 1,\n",
    "                \"lr_warmup\" : 1000,\n",
    "                \"gradient_clipping\" : 1.0,\n",
    "                \"input_dir\": \"./text_data/doc_embs_padding_large.npy\",\n",
    "                \"label_dir\": \"../../Price_Data/volitility_following_30days.npy\",\n",
    "                \"label_dir_b\": \"../../Price_Data/volitility_single_30days.npy\",\n",
    "                \"alpha\" : i,\n",
    "                \"gpu\": True,\n",
    "                \"save\": False\n",
    "        })\n",
    "\n",
    "        evaluation = run_gpu.go(args)\n",
    "        print('Results in alpha = ',i)\n",
    "        print(evaluation)\n",
    "        best_alpha['alpha'].append(i)\n",
    "        best_alpha['best'].append(evaluation['Test Accuracy'].iloc[0])\n",
    "        \n",
    "best_alpha = pd.DataFrame(best_alpha)\n",
    "best_alpha.sort_values([\"best\"],ascending=True,inplace=True)\n",
    "best_alpha.to_csv('./results/30_days_result.csv')\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
